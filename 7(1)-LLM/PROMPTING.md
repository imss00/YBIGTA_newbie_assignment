# GSM8K 벤치마크 프롬프팅 기법별 성능 분석 보고서

**작성자:** YBIGTA 28기 인공지능학과 임수빈

## 1. Prompting Accuracy 결과

Llama-3.1-8b-instant 모델을 사용하여 GSM8K 데이터셋에서 추출한 50개의 샘플을 대상으로 실험을 진행한 결과는 아래와 같다.

| Technique | 0-Shot Acc | 3-Shot Acc | 5-Shot Acc |
| **Direct Prompting** | 82.00% | 82.00% | 76.00% |
| **CoT Prompting** | 64.00% | 70.00% | 64.00% |

## 2. Cot Prompting이 Direct Prompting보다 우수한 이유

Chain-of-Thought (CoT)기법은 모델이 최종 정답을 내기 전 논리적인 중간 추론 과정을 생성하도록 유도한다. 이를 통해 크게 3가지의 이점을 얻을 수 있다.

1) 복잡한 문제 해결 능력: 
수학 문제처럼 다단계 연산이 필요한 경우, 결과만 바로 도출하기보다 단계를 분해하여 해결함으로써 연산 오류를 줄인다.
2) 추론의 투명성: 
정답에 도달한 근거를 확인할 수 있어 모델의 논리적 모순을 파악하기 유리하다.
3) 연산 시간 확보: 
텍스트 생성 시 풀이 과정을 상세히 적게 함으로써 모델이 충분한 계산 과정을 거치게 하는 효과가 있다.

## 3. My Prompting 기법의 차별점 
본 과제에서 설계한 My Prompting은 기존 CoT의 단점을 보완하는 방향으로 설계되었다.

우선, GSM8K 원본 데이터에 포함된 `<<...>>`와 같은 계산용 태그를 제거하는 데이터 정제 단계를 적용했다. 계산용 태그를 제거하는 것을 통해 모델이 불필요한 형식에 구애받지 않고 논리 전개에만 집중할 수 있게 하였다.

그 다음으로는 `Instruction`, `Example`, `Solution`, `Answer`로 이어지는 명확한 구분자를 사용하여 모델의 출력 일관성을 극대화 하고자 했다.

세 번째로는, 지시문에 "Examine the question carefully"와 같은 문구를 포함하고, 질문 직후 "Let's think step by step"을 배치하여 0-Shot 환경에서도 강력한 추론 능력을 발휘하도록 설계했다.

마지막으로는, 하이퍼파라미터 `temperature`를 조정하고 정답 형식을 `Answer: [number]`로 강제하여 파싱 오류를 차단하였다. 

정리하자면, 기존 프롬프트의 구조적 결함과 불필요한 데이터 노이즈와 같은 부분들을 보완하여 조금 더 정확도 높은 사고를 통한 결과치를 내놓을 수 있도록 보완하였다.


## 4. 결론
실험 결과, 모델의 특성에 맞춰 노이즈를 제거하고 사고 과정을 체계적으로 가이드한 My Prompting이 기존 기법들을 뛰어넘는 성과를 보였다. 