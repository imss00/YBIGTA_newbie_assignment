{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53cd899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /opt/anaconda3/lib/python3.13/site-packages (1.0.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.3.5)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.13/site-packages (4.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (2.10.5)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.13/site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/anaconda3/lib/python3.13/site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.21.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq python-dotenv numpy tqdm datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249253df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(0)\n",
    "\n",
    "client = Groq()\n",
    "gsm8k_dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "\n",
    "gsm8k_train = gsm8k_dataset[\"train\"]\n",
    "gsm8k_test  = gsm8k_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_using_Llama(\n",
    "        prompt: str,\n",
    "        model: str = \"llama-3.1-8b-instant\"\n",
    "    ):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant that solves math problems.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0.3, ### 수정해도 됩니다!\n",
    "            stream=False\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef65ad3",
   "metadata": {},
   "source": [
    "#### 응답 잘 나오는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37fad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world. I'm here to help with any math problems you'd like to solve. What kind of math are you working on today?\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_using_Llama(\n",
    "    prompt=\"Hello world!\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988803ae",
   "metadata": {},
   "source": [
    "#### GSM8K 데이터셋 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd177eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question]\n",
      "Janet’s ducks lay 16 eggs per day\n",
      " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
      " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
      " How much in dollars does she make every day at the farmers' market?\n",
      "====================================================================================================\n",
      "[Answer]\n",
      "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
      "#### 18\n"
     ]
    }
   ],
   "source": [
    "print(\"[Question]\")\n",
    "for l in gsm8k_test['question'][0].split(\".\"):\n",
    "    print(l)\n",
    "print(\"=\"*100)\n",
    "print(\"[Answer]\")\n",
    "print(gsm8k_test['answer'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabe66c",
   "metadata": {},
   "source": [
    "#### Util 함수들\n",
    "- extract_final_answer: LLM의 응답을 parse하여 최종 결과만 추출 (정답과 비교하기 위해)\n",
    "- run_benchmark_test: 벤치마크 테스트\n",
    "- save_final_result: 결과물 제출을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c10811",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수정해도 됩니다!\n",
    "def extract_final_answer(response: str):\n",
    "    regex = r\"(?:Answer:|Model response:)\\s*\\$?([0-9,]+)\\b|([0-9,]+)\\s*(meters|cups|miles|minutes)\"\n",
    "    matches = re.finditer(regex, response, re.MULTILINE)\n",
    "    results = [match.group(1) if match.group(1) else match.group(2).replace(\",\", \"\") for match in matches]\n",
    "\n",
    "    if len(results) == 0:\n",
    "        additional_regex = r\"\\$?([0-9,]+)\"\n",
    "        additional_matches = re.finditer(additional_regex, response, re.MULTILINE)\n",
    "        results.extend([match.group(1).replace(\",\", \"\") for match in additional_matches])\n",
    "\n",
    "    return results[-1] if results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e3a05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수정해도 됩니다!\n",
    "import time\n",
    "\n",
    "def run_benchmark_test(\n",
    "        dataset,\n",
    "        prompt: str,\n",
    "        model: str = \"llama3-8b-8192\",\n",
    "        num_samples: int = 50,\n",
    "        VERBOSE: bool = False\n",
    "    ):\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(min(num_samples, len(dataset)))):\n",
    "        time.sleep(2) # RPM 30 제한 피하기 위한 것\n",
    "\n",
    "        question = dataset[i][\"question\"]\n",
    "        correct_answer = float(re.findall(r'\\d+(?:\\.\\d+)?', dataset[i][\"answer\"].split('####')[-1])[0])\n",
    "\n",
    "        response = generate_response_using_Llama(\n",
    "            prompt=prompt.format(question=question),\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        if response:\n",
    "            predicted_answer_str = extract_final_answer(response)\n",
    "            try:\n",
    "                predicted_answer = float(str(predicted_answer_str).replace(\",\", \"\")) if predicted_answer_str else None\n",
    "            except ValueError:\n",
    "                predicted_answer = None\n",
    "\n",
    "            is_correct = False\n",
    "            if predicted_answer is not None:\n",
    "                is_correct = abs(predicted_answer - correct_answer) < 1e-5\n",
    "            \n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "            results.append({\n",
    "                'question': question,\n",
    "                'correct_answer': correct_answer,\n",
    "                'predicted_answer': predicted_answer,\n",
    "                'response': response,\n",
    "                'correct': is_correct\n",
    "            })\n",
    "\n",
    "            if (i + 1) % 5 == 0:\n",
    "                current_acc = correct/total if total > 0 else 0\n",
    "                print(f\"Progress: [{i+1}/{num_samples}]\")\n",
    "                print(f\"Current Acc.: [{current_acc:.2%}]\")\n",
    "\n",
    "    return results, correct/total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e63f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_result(results: List[Dict[str, Any]], accuracy: float, filename: str) -> None:\n",
    "    result_str = f\"====== ACCURACY: {accuracy} ======\\n\\n\"\n",
    "    result_str += f\"[Details]\\n\"\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        result_str += f\"Question {idx+1}: {result['question']}\\n\"\n",
    "        result_str += f\"Correct Answer: {result['correct_answer']}\\n\"\n",
    "        result_str += f\"Predicted Answer: {result['predicted_answer']}\\n\"\n",
    "        result_str += f\"Correct: {result['correct']}\\n\\n\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498f9ed",
   "metadata": {},
   "source": [
    "#### Direct prompting with few-shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_direct_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "\n",
    "    prompt = \"Instruction:\\nSolve the following mathematical question and generate ONLY the answer after a tag, 'Answer:' without any rationale.\\n\"\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        cur_question = train_dataset['question'][i]\n",
    "        cur_answer = train_dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:19,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:17,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:11<00:12,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:13<00:09,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:16<00:06,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:18<00:04,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:20<00:02,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 어떤 방식으로 저장되는지 확인해보세요!\n",
    "PROMPT = construct_direct_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    # model=\"llama-3.1-8b-instant\",\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=10\n",
    ")\n",
    "save_final_result(results, accuracy, \"example.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41874896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Running Direct Prompting: 0 Shot****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:13<01:57,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:26<01:41,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:38<01:29,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [73.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:58<02:15,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:10<01:08,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:30<01:22,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [76.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:42<00:42,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:56<00:27,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:09<00:12,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:21<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [82.00%]\n",
      "Saved: direct_prompting_0.txt (Accuracy: 82.00%)\n",
      "****Running Direct Prompting: 3 Shot****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:16<02:50,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [100.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:44<03:51,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:05<02:37,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [73.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:25<02:00,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [75.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:43<01:25,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [76.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [02:02<01:15,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [02:21<00:57,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [82.86%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [02:41<00:39,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [82.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [03:01<00:20,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [82.22%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:20<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [82.00%]\n",
      "Saved: direct_prompting_3.txt (Accuracy: 82.00%)\n",
      "****Running Direct Prompting: 5 Shot****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:25<03:51,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [100.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:52<03:31,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:19<03:12,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [73.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:51<03:38,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [75.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [02:23<02:21,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [72.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [02:48<01:44,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [76.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [03:09<01:07,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [03:36<00:51,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [04:02<00:26,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [75.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:28<00:00,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [76.00%]\n",
      "Saved: direct_prompting_5.txt (Accuracy: 76.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot direct prompting을 통해 벤치마크 테스트를 한 후, 각각 direct_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 direct_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "shots = [0, 3, 5]\n",
    "\n",
    "for shot in shots:\n",
    "    print(f\"****Running Direct Prompting: {shot} Shot****\")\n",
    "\n",
    "    current_prompt = construct_direct_prompt(shot)\n",
    "    \n",
    "    # 테스트 실행 (num_samples=50) \n",
    "    res, acc = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=current_prompt,\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        num_samples=50\n",
    "    )\n",
    "    \n",
    "    # 결과 저장\n",
    "    file_name = f\"direct_prompting_{shot}.txt\"\n",
    "    save_final_result(res, acc, file_name)\n",
    "    print(f\"Saved: {file_name} (Accuracy: {acc:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd21d1",
   "metadata": {},
   "source": [
    "### Chain-of-Thought prompting with few-shot example\n",
    "```text\n",
    "[Question]\n",
    "Janet’s ducks lay 16 eggs per day\n",
    " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
    " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
    " How much in dollars does she make every day at the farmers' market?\n",
    "====================================================================================================\n",
    "[Answer]\n",
    "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
    "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
    "#### 18\n",
    "```\n",
    "\n",
    "[Answer] 아래의 정답을 도출하는 과정을 예시로 달아주면 CoT의 few shot이 되겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a989e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_CoT_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "    prompt = (\n",
    "        \"Instruction:\\n\"\n",
    "        \"Solve the following mathematical questions step by step. \"\n",
    "        \"Provide the full reasoning and then give the final answer after the tag '#### '.\\n\"\n",
    "    )\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        cur_question = train_dataset[idx]['question']\n",
    "        cur_answer = train_dataset[idx]['answer']\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:\\n{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c510586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Running CoT Prompting: 0 Shot ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:14<02:04,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:27<01:46,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:40<01:29,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:54<01:20,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:07<01:05,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [56.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:20<00:51,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:33<00:37,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [65.71%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:46<00:26,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [62.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:58<00:12,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [62.22%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:11<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [64.00%]\n",
      "Saved: CoT_prompting_0.txt (Accuracy: 64.00%)\n",
      "**** Running CoT Prompting: 3 Shot ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:12<01:53,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [100.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:25<01:42,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:38<01:33,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [86.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:51<01:19,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [75.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:04<01:04,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [64.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:17<00:49,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:29<00:37,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [71.43%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:50<00:37,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [67.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:03<00:14,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [68.89%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:24<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [70.00%]\n",
      "Saved: CoT_prompting_3.txt (Accuracy: 70.00%)\n",
      "**** Running CoT Prompting: 5 Shot ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:13<02:02,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:26<01:45,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:40<01:32,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [73.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:52<01:17,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:05<01:01,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:17<00:50,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [63.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:30<00:37,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [68.57%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:43<00:27,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [62.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:56<00:13,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [62.22%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:09<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [64.00%]\n",
      "Saved: CoT_prompting_5.txt (Accuracy: 64.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot CoT prompting을 통해 벤치마크 테스트를 한 후, 각각 CoT_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 CoT_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "for shot in [0, 3, 5]:\n",
    "    print(f\"**** Running CoT Prompting: {shot} Shot ****\")\n",
    "    prompt_text = construct_CoT_prompt(shot)\n",
    "    \n",
    "    results, accuracy = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=prompt_text,\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        num_samples=50\n",
    "    )\n",
    "\n",
    "    save_final_result(results, accuracy, f\"CoT_prompting_{shot}.txt\")\n",
    "    print(f\"Saved: CoT_prompting_{shot}.txt (Accuracy: {accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c45b54",
   "metadata": {},
   "source": [
    "### Construct your prompt!!\n",
    "\n",
    "목표: 본인만의 프롬프트를 통해 정답률을 더 끌어올려보기!\n",
    "- gsm8k의 train 데이터셋에서 예시를 가져온 다음 (자유롭게!)\n",
    "- 그 예시들에 대한 풀이 과정을 만들어주세요!\n",
    "- 모든 것들이 자유입니다! Direct Prompting, CoT Prompting을 한 결과보다 정답률만 높으면 돼요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09062c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_my_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "    # 실험적으로 성능이 좋았던 고정 예시 인덱스나 랜덤 샘플링 사용\n",
    "    sampled_indices = random.sample(range(len(train_dataset)), num_examples)\n",
    "\n",
    "    # 지시사항을 간결하고 강력하게 변경\n",
    "    prompt = (\n",
    "        \"Instruction:\\n\"\n",
    "        \"Solve the following grade school math problem. \\n\"\n",
    "        \"Examine the question carefully, write your step-by-step solution, and provide the final answer.\\n\"\n",
    "        \"Your final answer must be a single number preceded by 'Answer: '.\\n\"\n",
    "    )\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        cur_question = train_dataset[idx]['question']\n",
    "        raw_answer = train_dataset[idx]['answer']\n",
    "        \n",
    "        # CoT 풀이에서 <<...>> 태그를 제거하여 가독성 증대\n",
    "        reasoning = re.sub(r\"<<.*?>>\", \"\", raw_answer.split('####')[0].strip())\n",
    "        final_val = raw_answer.split('####')[-1].strip()\n",
    "\n",
    "        prompt += f\"\\nExample {i+1}:\\n\"\n",
    "        prompt += f\"Question: {cur_question}\\n\"\n",
    "        prompt += f\"Solution: {reasoning}\\n\"\n",
    "        prompt += f\"Answer: {final_val}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion: {question}\\nSolution:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ac2b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Running My Prompting (Improved): 0 Shot ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [01:31<18:22, 24.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [100.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [03:56<19:14, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [06:15<16:09, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [08:34<13:42, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [10:51<10:52, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [76.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [13:11<09:13, 27.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [15:16<06:17, 25.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [82.86%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [17:31<04:31, 27.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [85.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [20:03<02:28, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [84.44%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [22:27<00:00, 26.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [84.00%]\n",
      "Final Acc: 84.00%\n",
      "**** Running My Prompting (Improved): 3 Shot ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:02<01:47,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499987, Requested 711. Please try again in 2m0.6144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:04<01:47,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499975, Requested 674. Please try again in 1m52.147199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:06<01:43,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499962, Requested 697. Please try again in 1m53.8752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:08<01:41,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499949, Requested 682. Please try again in 1m49.0368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:11<01:40,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499936, Requested 756. Please try again in 1m59.5776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:13<01:37,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499923, Requested 702. Please try again in 1m48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:15<01:35,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499911, Requested 689. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:17<01:32,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499898, Requested 713. Please try again in 1m45.5808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:19<01:30,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499885, Requested 749. Please try again in 1m49.5552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:22<01:28,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499872, Requested 705. Please try again in 1m39.7056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:24<01:26,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499859, Requested 706. Please try again in 1m37.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:26<01:24,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499846, Requested 709. Please try again in 1m35.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:28<01:21,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499834, Requested 714. Please try again in 1m34.6944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:31<01:20,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499821, Requested 705. Please try again in 1m30.8928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:33<01:19,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499808, Requested 697. Please try again in 1m27.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:35<01:16,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499794, Requested 738. Please try again in 1m31.9296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:37<01:13,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499781, Requested 698. Please try again in 1m22.7712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:40<01:11,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499769, Requested 700. Please try again in 1m21.0432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:42<01:08,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499756, Requested 676. Please try again in 1m14.6496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:44<01:07,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499742, Requested 712. Please try again in 1m18.4512s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:46<01:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499729, Requested 708. Please try again in 1m15.5136s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:48<01:02,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499717, Requested 691. Please try again in 1m10.5024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:51<01:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499704, Requested 703. Please try again in 1m10.3296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:53<00:58,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499691, Requested 686. Please try again in 1m5.1456s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:55<00:55,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499678, Requested 684. Please try again in 1m2.5536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:57<00:53,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499665, Requested 711. Please try again in 1m4.972799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [01:00<00:50,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499653, Requested 711. Please try again in 1m2.8992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [02:05<05:15, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499986, Requested 695. Please try again in 1m57.6768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [02:07<03:43, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499973, Requested 714. Please try again in 1m58.7136s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [02:09<02:41,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499961, Requested 683. Please try again in 1m51.2832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [02:12<01:59,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499947, Requested 708. Please try again in 1m53.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [02:14<01:29,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499935, Requested 688. Please try again in 1m47.6544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [02:16<01:09,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499922, Requested 675. Please try again in 1m43.1616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [02:18<00:55,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499909, Requested 688. Please try again in 1m43.1616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [02:20<00:45,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499896, Requested 696. Please try again in 1m42.297599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [02:23<00:38,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499883, Requested 689. Please try again in 1m38.8416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [02:25<00:32,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499870, Requested 708. Please try again in 1m39.8784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [02:27<00:28,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499857, Requested 691. Please try again in 1m34.6944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [02:29<00:24,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499845, Requested 720. Please try again in 1m37.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:32<00:21,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499832, Requested 692. Please try again in 1m30.5472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [02:34<00:18,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499819, Requested 772. Please try again in 1m42.1248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [02:36<00:16,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499806, Requested 728. Please try again in 1m32.2752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [02:38<00:13,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499793, Requested 701. Please try again in 1m25.363199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:41<00:11,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499780, Requested 720. Please try again in 1m26.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [02:43<00:09,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499767, Requested 740. Please try again in 1m27.6096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [02:45<00:06,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499754, Requested 737. Please try again in 1m24.8448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [02:47<00:04,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499741, Requested 694. Please try again in 1m15.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [02:49<00:02,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499728, Requested 684. Please try again in 1m11.1936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:52<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499715, Requested 690. Please try again in 1m9.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Final Acc: 100.00%\n",
      "**** Running My Prompting (Improved): 5 Shot ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:02<01:47,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499702, Requested 811. Please try again in 1m28.6464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:04<01:45,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499690, Requested 774. Please try again in 1m20.1792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:06<01:43,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499677, Requested 797. Please try again in 1m21.907199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:08<01:41,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499664, Requested 782. Please try again in 1m17.0688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:11<01:39,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499651, Requested 856. Please try again in 1m27.6096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:13<01:36,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499639, Requested 802. Please try again in 1m16.204799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:15<01:34,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499626, Requested 789. Please try again in 1m11.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:17<01:32,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499613, Requested 813. Please try again in 1m13.6128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:19<01:30,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499601, Requested 849. Please try again in 1m17.759999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:21<01:27,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499588, Requested 805. Please try again in 1m7.910399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:24<01:25,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499575, Requested 806. Please try again in 1m5.8368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:26<01:23,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499562, Requested 809. Please try again in 1m4.1088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:28<01:21,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499550, Requested 814. Please try again in 1m2.8992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:34<08:49, 15.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499985, Requested 797. Please try again in 2m15.1296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [01:36<06:22, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499972, Requested 838. Please try again in 2m19.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [01:38<04:41,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499959, Requested 798. Please try again in 2m10.809599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [01:41<03:34,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499945, Requested 800. Please try again in 2m8.735999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [01:43<02:45,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499932, Requested 776. Please try again in 2m2.3424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:45<02:13,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499919, Requested 812. Please try again in 2m6.3168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:47<01:49,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499906, Requested 808. Please try again in 2m3.3792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [01:50<01:36,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499892, Requested 791. Please try again in 1m58.0224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [01:52<01:22,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499878, Requested 803. Please try again in 1m57.6768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [01:54<01:13,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499865, Requested 786. Please try again in 1m52.4928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:57<01:06,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499852, Requested 784. Please try again in 1m49.900799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [01:59<01:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499839, Requested 811. Please try again in 1m52.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [02:01<00:57,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499825, Requested 811. Please try again in 1m49.900799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [02:04<00:54,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499811, Requested 803. Please try again in 1m46.0992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [02:06<00:50,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499798, Requested 795. Please try again in 1m42.4704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [02:08<00:46,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499785, Requested 814. Please try again in 1m43.5072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [02:11<00:44,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499772, Requested 783. Please try again in 1m35.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [02:13<00:44,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499758, Requested 808. Please try again in 1m37.8048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [02:15<00:40,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499743, Requested 788. Please try again in 1m31.7568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [02:18<00:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499730, Requested 775. Please try again in 1m27.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [02:20<00:34,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499717, Requested 788. Please try again in 1m27.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [02:22<00:31,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499705, Requested 796. Please try again in 1m26.5728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [02:24<00:29,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499692, Requested 789. Please try again in 1m23.1168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [02:27<00:26,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499679, Requested 808. Please try again in 1m24.1536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [02:29<00:25,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499666, Requested 791. Please try again in 1m18.9696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [02:31<00:23,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499652, Requested 820. Please try again in 1m21.5616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:34<00:20,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499639, Requested 792. Please try again in 1m14.4768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [02:36<00:18,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499626, Requested 872. Please try again in 1m26.054399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [02:38<00:15,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499613, Requested 828. Please try again in 1m16.204799999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [02:40<00:13,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499600, Requested 801. Please try again in 1m9.2928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:43<00:11,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499587, Requested 820. Please try again in 1m10.3296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [02:45<00:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499574, Requested 840. Please try again in 1m11.5392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [02:47<00:06,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499561, Requested 837. Please try again in 1m8.7744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [03:53<00:15, 15.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499985, Requested 784. Please try again in 2m12.8832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:55<00:00,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kgbdfh72fb1sbxh5ek4fevpd` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499973, Requested 790. Please try again in 2m11.846399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Final Acc: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 만든 0 shot, 3 shot, 5 shot example과 프롬프트를 통해 벤치마크 테스트를 한 후, 각각 My_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 My_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "for shot in [0, 3, 5]:\n",
    "    print(f\"**** Running My Prompting (Improved): {shot} Shot ****\")\n",
    "    prompt_text = construct_my_prompt(shot)\n",
    "    results, accuracy = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=prompt_text,\\\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, accuracy, f\"My_prompting_{shot}.txt\")\n",
    "    print(f\"Final Acc: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dbfcb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Final Accuracy Summary Table ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technique</th>\n",
       "      <th>0-Shot Acc</th>\n",
       "      <th>3-Shot Acc</th>\n",
       "      <th>5-Shot Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direct_prompting</td>\n",
       "      <td>82.00%</td>\n",
       "      <td>82.00%</td>\n",
       "      <td>76.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CoT_prompting</td>\n",
       "      <td>64.00%</td>\n",
       "      <td>70.00%</td>\n",
       "      <td>64.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My_prompting</td>\n",
       "      <td>84.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Technique 0-Shot Acc 3-Shot Acc 5-Shot Acc\n",
       "0  direct_prompting     82.00%     82.00%     76.00%\n",
       "1     CoT_prompting     64.00%     70.00%     64.00%\n",
       "2      My_prompting     84.00%    100.00%    100.00%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 데이터를 담을 리스트\n",
    "summary_data = []\n",
    "\n",
    "techniques = [\"direct_prompting\", \"CoT_prompting\", \"My_prompting\"]\n",
    "shots = [0, 3, 5]\n",
    "\n",
    "for tech in techniques:\n",
    "    row = {\"Technique\": tech}\n",
    "    for shot in shots:\n",
    "        filename = f\"{tech}_{shot}.txt\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.readline() # 첫 번째 줄에 ACCURACY 정보가 있음\n",
    "                # \"====== ACCURACY: 0.82 ======\" 에서 숫자만 추출\n",
    "                acc_match = re.search(r\"ACCURACY: ([\\d.]+)\", content)\n",
    "                accuracy = float(acc_match.group(1)) if acc_match else 0.0\n",
    "                row[f\"{shot}-Shot Acc\"] = f\"{accuracy:.2%}\"\n",
    "        else:\n",
    "            row[f\"{shot}-Shot Acc\"] = \"N/A\"\n",
    "    summary_data.append(row)\n",
    "\n",
    "# 데이터프레임 생성 및 출력\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"\\n[ Final Accuracy Summary Table ]\")\n",
    "display(df_summary) # 주피터 노트북에서 예쁜 표로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd837d7",
   "metadata": {},
   "source": [
    "### 보고서 작성하기\n",
    "#### 아래의 내용이 포함되면 됩니다!\n",
    "\n",
    "1. Direct Prompting, CoT Prompting, My Prompting을 0 shot, 3 shot, 5 shot 정답률을 표로 보여주세요!\n",
    "2. CoT Prompting이 Direct Prompting에 비해 왜 좋을 수 있는지에 대해서 서술해주세요!\n",
    "3. 본인이 작성한 프롬프트 기법이 CoT에 비해서 왜 더 좋을 수 있는지에 대해서 설명해주세요!\n",
    "4. 최종적으로, `PROMPTING.md`에 보고서를 작성해주세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
